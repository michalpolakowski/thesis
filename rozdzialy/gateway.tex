\chapter {Moduł Bramy}

Moduł bramy ma za zadanie optymalizację i dystrybucję ruchu sieciowego.
Używa NGINX jako serwera pośredniczącego aby zapewnić możliwie najkrótszy czas
odpowiedzi dla użytkownika aplikacji.

W związku z tym możemy wyszczególnić 5 głowne zadania, jakie serwer bramy wykonuje:


\begin{itemize}
  \item Load balancing
  \item Cachowanie
  \item Anonimizacja użytkownika
  \item Zwiększenie wydajności
  \item Skalowalność
\end{itemize}

\section{Load balancing}

Load balancing to technika redukowania obciążenia wynikającego z ilości zapytań jakie serwer musi obsłużyć poprzez dystrybuowanie ruchu na więcej niż jedną instancję, która jest w stanie takie zapytania obsłużyć. Nasz system musi zapewniać użytkownikowi poczucie lekkości niezależnie od ilości aktualnie nawiązanych połączeń. Aby rzeczywiście znalezienie najlepszego dla wybranej rzeczy dopasowania wiązało się z oszczędnością czasu, z perspektywy infrastruktury musimy zapewnić możliwie najkrótszy czas odpowiedzi.
Na serwerze bramy do dystrybucji ruchu wybrany został algorytm karuzelowy - wszystkie procesy mają ten sam priorytet.
\begin{lstlisting}
  http {
    upstream app1 {
      server srv1.example.com
      server srv1.example.com
      server srv1.example.com
    }
  }
\end{lstlisting}

\section{Caching}

Funkcjonalność aplikacji oraz korzyści jakie daje ona użytkownikowi opierają się między innymi na możliwości szybkiego porównania i wyciągnięcia wniosków dotyczących potencjalnego dopasowania. Możliwe jest to dzięki wyświetleniu zdjęcia znalezionego produktu. Nieżadko może się zdażyć, że propozycje dopasowań będą się powtarzać. Daje to możliwość cachowania plików statycznych, dzięki czemu kolejne rządanie HTTP po taki zasób będzie serwowane bezpośrednio z dysku twardego serwera bramy, a nie z serwera docelowego.
Co więcej, NGINX daje udostępnia interfejs do ustawienia cachowania po stronie klienta, dzięki czemu zasoby statyczne w razie rządania HTTP będą pobierane bezpośrednio z pamięci podręcznej przeglądarki.

\begin{lstlisting}
  location ~* \.(jpg|jpg|png|gif|ico)$$ {
    expires 30d;
  }
  
  location ~* \.(css|js)$$ {
    expires 7d;
  }
\end{lstlisting}

\section{Anonimizacja}
Niezbędnym jest zapewnienie bezpieczeństwa użytkownika i systemu.
Bezpieczeństo użytkownika jest rozumiane przez nas jako anonimizacja jego wyszukiwań. W przypadku korzystania z NGINX jako serwera pośredniczącego anonimizacja wynika naturalnie z architektury systemu.
Rządania HTTP po zasoby udostępniane przez sklepy internetowe są wykonywane z adresem logicznym bramy, a nie użytkownika końcowego.
Dzięki temu sklepy pozbawione są możliwości targetowania reklam dla użytkownika  biorąc pod uwagę jego poprzednie wizyty. Dzięki temu użytkownikowi aplikacji nie będą prezentowane reklamy powiązane z wyszukiwanym produktem - nie zapewniają one w żaden sposób, że reklamy będą dotyczyć rzeczy pasujących, a jedynie podobnych, lub nawet tych samych.

\section{Zwiększenie wydajności}
Pośród ogromu możliwości, jakie serwer NGINX daje w kontekście optymalizacji ruchu, wybraliśmy kilka, które w najbardziej bezpośredni sposób wpływają na wydajność naszej infrastruktury:

\begin{enumerate}
\item
Ustawienie liczby procesów potomnych serwera na podstawie liczby CPU oraz dysków twardych
\begin{lstlisting}
worker_processes auto;
\end{lstlisting}
\item
Zwiększenie liczby operacji weścia/wyjścia na dysku twardym przez wyłączenie logowania
\begin{lstlisting}
error_log /var/log/nginx/error.log crit;
access_log off;
\end{lstlisting}
\item
Wymuszenie na  wysłania danych z bufora tak szybko jak to możliwe, pomijając algorytm Nagle'a, według którego pakiet, który jest za mały, czeka według standardowej implementacji UNIX 200 milisekund na wypełnienie.
\begin{lstlisting}
tcp_nodelay on;
\end{lstlisting}
Wymuszenie na pakiecie blokady zanim osiągnie maksymalny rozmiar
\begin{lstlisting}
tcp_nopush on;
\end{lstlisting}
\end{enumerate}

\section{Skalowalność}
Wraz ze wzrostem zainteresowania systemem, musimy przewidzieć, że w pewnym momencie obecna architektura może nie być wystarczająca, aby zapewnić stabilność i wysoką wydajność. Serwer NGINX jest zorientowany wokół jednego procesu głównego i wielu procesów potomnych zależnie od liczby rdzeni CPU i dysków twardych. W miarę potrzeby możemy zwiększyć liczbę rdzeni procesora, a przez to zwiększyć też liczbę procesów potomnych.
Infrastruktura jest zorientowana zarówno wokół konieczności skalowalności wertykalnej, ale również horyzontalnej. Zwiększenie liczby procesów na które dystrybuowany jest ruch w procesie load-balancingu również jest możliwe i zapewni stabilność w przypadku potrzeby skalowania.



